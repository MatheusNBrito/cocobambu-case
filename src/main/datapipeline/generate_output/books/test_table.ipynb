{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Configurando logging para DEBUG\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Inicializar o SparkSession com logs mais detalhados\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PostgreSQL Test\") \\\n",
    "    .config(\"spark.jars\", \"C:/Projetos/postgresql-42.7.4.jar\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"SparkSession criada com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Definindo o nível de log para DEBUG\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# Agora execute novamente o código\n",
    "test_data = [(\"João\", 25), (\"Maria\", 30), (\"José\", 28)]  # Dados simples\n",
    "columns = [\"name\", \"age\"]\n",
    "test_df = spark.createDataFrame(test_data, columns)\n",
    "\n",
    "try:\n",
    "    test_df.write.parquet(\"test_data.parquet\")\n",
    "    \n",
    "    print(\"Dados de teste escritos com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao salvar dados no banco de dados: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações do banco de dados PostgreSQL\n",
    "db_url = \"jdbc:postgresql://localhost:5432/cocobambu_case\"  # Altere o banco conforme necessário\n",
    "db_properties = {\n",
    "    \"user\": \"postgres\",  # Substitua com o seu usuário\n",
    "    \"password\": \"1475963\",  # Substitua com a sua senha\n",
    "    \"driver\": \"org.postgresql.Driver\"  # Driver JDBC do PostgreSQL\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PostgreSQL Test\") \\\n",
    "    .config(\"spark.jars\", \"C:/Projetos/postgresql-42.7.4.jar\") \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-Dlog4j.configuration=log4j.properties\") \\\n",
    "    .config(\"spark.sql.debug.maxToStringFields\", 1000) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Configurações do banco de dados PostgreSQL\n",
    "db_url = \"jdbc:postgresql://localhost:5432/cocobambu_case\"  # Altere o banco conforme necessário\n",
    "db_properties = {\n",
    "    \"user\": \"postgres\",  # Substitua com o seu usuário\n",
    "    \"password\": \"1475963\",  # Substitua com a sua senha\n",
    "    \"driver\": \"org.postgresql.Driver\"  # Driver JDBC do PostgreSQL\n",
    "}\n",
    "\n",
    "# Caminho para o driver JDBC PostgreSQL\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PostgreSQL Test\") \\\n",
    "    .config(\"spark.jars\", \"C:/Projetos/postgresql-42.7.4.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Testando a Conexão - Lendo uma tabela existente no banco\n",
    "try:\n",
    "    # Tenta ler dados da tabela \"FactSales\"\n",
    "    test_df = spark.read.jdbc(\n",
    "        url=db_url,\n",
    "        table=\"FactSales\",  # Substitua com o nome de uma tabela que exista no banco\n",
    "        properties=db_properties\n",
    "    )\n",
    "    \n",
    "    # Exibe as primeiras 5 linhas para verificar se a leitura foi bem-sucedida\n",
    "    print(\"Conexão bem-sucedida! Exibindo as primeiras 5 linhas da tabela 'FactSales':\")\n",
    "    test_df.show(5)\n",
    "except Exception as e:\n",
    "    print(\"Erro ao conectar e ler os dados:\", e)\n",
    "\n",
    "# Testando a Escrita no Banco de Dados - Criação de uma tabela de teste\n",
    "try:\n",
    "    # Criando um DataFrame de teste simples\n",
    "    test_data = [(\"João\", 25), (\"Maria\", 30), (\"José\", 28)]\n",
    "    columns = [\"nome\", \"idade\"]\n",
    "    test_df = spark.createDataFrame(test_data, columns)\n",
    "\n",
    "    # Escrevendo os dados na tabela \"TestTable\" no banco de dados PostgreSQL\n",
    "    test_df.write.jdbc(\n",
    "        url=db_url,\n",
    "        table=\"TestTable\",  # Nome da tabela de teste\n",
    "        mode=\"overwrite\",  # Use \"overwrite\" para sobrescrever ou \"append\" para adicionar\n",
    "        properties=db_properties\n",
    "    )\n",
    "\n",
    "    print(\"Dados de teste escritos na tabela 'TestTable' com sucesso!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Erro ao gravar os dados no banco de dados:\", e)\n",
    "\n",
    "# Finaliza a sessão Spark\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
